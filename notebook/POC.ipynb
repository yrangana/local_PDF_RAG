{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_community.document_loaders import OnlinePDFLoader\n",
    "from IPython.display import display as Markdown\n",
    "from tqdm.autonotebook import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = '../data/Think_and_Grow_Rich.pdf'\n",
    "\n",
    "# Local Pdf file uploads\n",
    "if local_path:\n",
    "    loader = UnstructuredPDFLoader(file_path=local_path)\n",
    "    data = loader.load()\n",
    "else:       \n",
    "    print(\"Upload a pdf file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models=[Model(model='nomic-embed-text:latest', modified_at=datetime.datetime(2025, 2, 1, 12, 20, 36, 7117, tzinfo=TzInfo(UTC)), digest='0a109f422b47e3a30ba2b10eca18548e944e8a23073ee3f3e947efcf3c45e59f', size=274302450, details=ModelDetails(parent_model='', format='gguf', family='nomic-bert', families=['nomic-bert'], parameter_size='137M', quantization_level='F16')), Model(model='llama3.3:latest', modified_at=datetime.datetime(2025, 1, 27, 13, 14, 5, 308781, tzinfo=TzInfo(UTC)), digest='a6eb4748fd2990ad2952b2335a95a7f952d1a06119a0aa6a2df6cd052a93a3fa', size=42520413916, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='70.6B', quantization_level='Q4_K_M')), Model(model='deepseek-r1:8b', modified_at=datetime.datetime(2025, 1, 27, 12, 24, 42, 88429, tzinfo=TzInfo(UTC)), digest='28f8fd6cdc677661426adab9338ce3c013d7e69a5bea9e704b364171a5d61a10', size=4920738407, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='8.0B', quantization_level='Q4_K_M')), Model(model='deepseek-r1:32b', modified_at=datetime.datetime(2025, 1, 26, 15, 14, 41, 779781, tzinfo=TzInfo(UTC)), digest='38056bbcbb2d068501ecb2d5ea9cea9dd4847465f1ab88c4d4a412a9f7792717', size=19851337640, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='32.8B', quantization_level='Q4_K_M')), Model(model='llava:34b', modified_at=datetime.datetime(2025, 1, 26, 15, 14, 41, 778801, tzinfo=TzInfo(UTC)), digest='3d2d24f4667475bd28d515495b0dcc03b5a951be261a0babdb82087fc11620ee', size=20166497526, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama', 'clip'], parameter_size='34B', quantization_level='Q4_0')), Model(model='phi4:latest', modified_at=datetime.datetime(2025, 1, 26, 15, 14, 41, 778931, tzinfo=TzInfo(UTC)), digest='ac896e5b8b34a1f4efa7b14d7520725140d5512484457fab45d2a4ea14c69dba', size=9053116391, details=ModelDetails(parent_model='', format='gguf', family='phi3', families=['phi3'], parameter_size='14.7B', quantization_level='Q4_K_M')), Model(model='qwen2:72b', modified_at=datetime.datetime(2025, 1, 26, 15, 14, 41, 779463, tzinfo=TzInfo(UTC)), digest='93563ef658b23ff5341f9d6b1660c62cfb903335c21bdb6113ef9c838e7fcf54', size=41231744117, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='72.7B', quantization_level='Q4_0')), Model(model='qwen2.5:0.5b', modified_at=datetime.datetime(2025, 1, 26, 15, 14, 41, 779261, tzinfo=TzInfo(UTC)), digest='a8b0c51577010a279d933d14c2a8ab4b268079d44c5c8830c0a93900f1827c67', size=397821319, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='494.03M', quantization_level='Q4_K_M')), Model(model='llama3.2-vision:90b', modified_at=datetime.datetime(2025, 1, 26, 15, 14, 41, 779130, tzinfo=TzInfo(UTC)), digest='d2a5e64c56a9cfed42fc0b8040a717e899d20646ce1ae8314bbe2e9a416f7eeb', size=54713024426, details=ModelDetails(parent_model='', format='gguf', family='mllama', families=['mllama', 'mllama'], parameter_size='87.7B', quantization_level='Q4_K_M')), Model(model='llama3.2-vision:latest', modified_at=datetime.datetime(2025, 1, 26, 15, 14, 41, 779066, tzinfo=TzInfo(UTC)), digest='085a1fdae525a3804ac95416b38498099c241defd0f1efc71dcca7f63190ba3d', size=7901829417, details=ModelDetails(parent_model='', format='gguf', family='mllama', families=['mllama', 'mllama'], parameter_size='9.8B', quantization_level='Q4_K_M'))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nomic embeddings found\n"
     ]
    }
   ],
   "source": [
    "# check ollama status\n",
    "import ollama as Ollama\n",
    "from ollama import Client\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "Client = Client(\n",
    "    host='http://localhost:11434',\n",
    ")\n",
    "\n",
    "print(Client.list())\n",
    "\n",
    "Ollama.pull('nomic-embed-text') # pulling nomic embeddings\n",
    "\n",
    "# check nomic embeddings are available\n",
    "models = Client.list()\n",
    "if str(models).find('nomic-embed-text') == -1:\n",
    "    print(\"Nomic embeddings not found\")\n",
    "else:\n",
    "    print(\"Nomic embeddings found\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First clean up any existing ChromaDB installations\n",
    "%pip uninstall -y chromadb\n",
    "%pip uninstall -y protobuf\n",
    "\n",
    "# 2. Install specific versions known to work together\n",
    "%pip install -q protobuf\n",
    "%pip install -q chromadb==0.4.22  # Using a stable older version\n",
    "%pip install -q langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Set the environment variable\n",
    "import os\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and chunk \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=7500, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try creating the vector database\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=OllamaEmbeddings(model=\"nomic-embed-text\"),\n",
    "    collection_name=\"local-rag\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM from Ollama\n",
    "local_model = \"phi4\"\n",
    "llm = ChatOllama(model=local_model, base_url = \"http://localhost:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
    "    different versions of the given user question to retrieve relevant documents from\n",
    "    a vector database. By generating multiple perspectives on the user question, your\n",
    "    goal is to help the user overcome some of the limitations of the distance-based\n",
    "    similarity search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    vector_db.as_retriever(), \n",
    "    llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")\n",
    "\n",
    "# RAG prompt\n",
    "template = \"\"\"Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The idea that \"you are the master of your fate\" stems from the belief that individuals have significant control over their own lives and destinies through their thoughts, actions, decisions, and attitudes. Here\\'s why this perspective holds weight:\\n\\n1. **Autosuggestion**: The principle of autosuggestion suggests that persistent thoughts can influence behavior and outcomes. By consciously choosing positive thoughts and affirmations, you can guide your actions toward desired goals.\\n\\n2. **Self-Confidence and Determination**: Building self-confidence empowers individuals to pursue their aspirations with determination. Believing in one\\'s ability to achieve a definite purpose is crucial for taking the necessary steps towards success.\\n\\n3. **Control Over Environment**: While external circumstances are often beyond control, you have the power to shape your environment by choosing where to focus attention and energy. This includes surrounding yourself with supportive people and environments that foster growth.\\n\\n4. **Proactive Attitude**: Taking responsibility for one\\'s life means being proactive rather than reactive. By setting goals, planning actions, and learning from experiences, individuals can steer their lives in preferred directions.\\n\\n5. **Learning from Mistakes**: Every experience offers a lesson. Embracing failures as opportunities to learn and grow contributes to personal development and better decision-making in the future.\\n\\n6. **Mental Resilience**: Developing mental resilience helps individuals face challenges with courage and optimism, allowing them to overcome obstacles rather than be defeated by them.\\n\\n7. **Ethical Success**: Building wealth or achieving success on a foundation of truth, justice, and mutual benefit creates sustainable and fulfilling outcomes. Positive relationships and ethical behavior attract cooperation and opportunities.\\n\\n8. **Self-Reflection**: Regularly assessing mental assets and liabilities enables individuals to identify areas for improvement and take corrective actions.\\n\\nBy harnessing these principles, you can become the master of your fate, taking control over how your life unfolds through conscious choices and positive thinking.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Why you are the master of your fate?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The book appears to explore themes related to success, personal development, and the power of ideas in generating wealth. It emphasizes concepts such as:\\n\\n1. **Imagination and Ideas**: The story of \"The Enchanted Kettle\" serves as an allegory for how a simple idea can lead to immense success and prosperity. This tale illustrates that it\\'s not just tangible assets but also creativity and innovative thinking that drive business growth.\\n\\n2. **Impact of a Single Idea**: The narrative demonstrates how one small, well-conceived idea can have far-reaching impactsâ€”creating jobs, fostering economic development, and bringing about positive changes in communities and industries.\\n\\n3. **Economic Prosperity During Hard Times**: The book underscores the resilience of businesses built on strong ideas, as evidenced by the continued success of the \"Enchanted Kettle\" company even during economic downturns.\\n\\n4. **Personal Growth and Relationships**: There\\'s an element of personal storytelling, highlighting how business ventures can intersect with personal lives and relationships, contributing to personal fulfillment beyond financial gains.\\n\\nOverall, the book seems to advocate for nurturing one\\'s imagination and the potential power within ideas to create transformative impacts both personally and globally.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is this book about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Think and Grow Rich,\" by Napoleon Hill, encapsulates a philosophy on success centered around transforming desires into tangible achievements through focused thought and action. The core principle is leveraging auto-suggestion to influence the subconscious mind, empowering individuals to harness their inner potential and align it with Infinite Intelligence for financial prosperity. The book emphasizes specialized knowledge over general knowledge, advocating for practical application toward wealth accumulation. It also highlights persistence, faith, and the belief that mastering one's destiny is possible through disciplined mental training and unwavering dedication to personal goals.\n",
      "\n",
      "(Note: While I summarized the key points from your provided excerpts, \"Think and Grow Rich\" has additional elements not covered here due to space constraints.)\n"
     ]
    }
   ],
   "source": [
    "output = chain.invoke(\"Summarize whole book into one paragraph less than 100 words\")\n",
    "\n",
    "# split output into chain of things and response\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The name of the book is \"Think and Grow Rich\" and the author is Napoleon Hill.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"WHats the name of this book and author? give me the answer in this format: 'The name of the book is <name> and the author is <author>'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
